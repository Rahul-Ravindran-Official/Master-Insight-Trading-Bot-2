{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Buy Prediction Algorithm NZD-USD\n",
    "This notebook aims to minimize the clasification loss between No Action and Buy Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"NZDUSD=X\"\n",
    "supporting_predictor_names = [\n",
    "    'RAW-EMA-2',\n",
    "    'RAW-EMA-3',\n",
    "    'RAW-EMA-5',\n",
    "    'RAW-EMA-7',\n",
    "    'RAW-EMA-21',\n",
    "    'RAW-EMA-50'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>diff-day-1</th>\n",
       "      <th>diff-day-2</th>\n",
       "      <th>diff-day-3</th>\n",
       "      <th>diff-day-4</th>\n",
       "      <th>...</th>\n",
       "      <th>EMA-7</th>\n",
       "      <th>EMA-21</th>\n",
       "      <th>EMA-50</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ADX</th>\n",
       "      <th>STD</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_buy</th>\n",
       "      <th>bb_sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.621504</td>\n",
       "      <td>0.623791</td>\n",
       "      <td>0.618506</td>\n",
       "      <td>0.619809</td>\n",
       "      <td>0.619809</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001695</td>\n",
       "      <td>-0.006208</td>\n",
       "      <td>-0.002933</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.154273</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>-0.008072</td>\n",
       "      <td>-0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.619617</td>\n",
       "      <td>0.620001</td>\n",
       "      <td>0.614817</td>\n",
       "      <td>0.618582</td>\n",
       "      <td>0.618582</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>-0.002922</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>-0.002052</td>\n",
       "      <td>0.500428</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.146584</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>-0.008291</td>\n",
       "      <td>-0.001994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.618697</td>\n",
       "      <td>0.620232</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.619310</td>\n",
       "      <td>0.619310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>-0.006707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.001272</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>-0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.619195</td>\n",
       "      <td>0.621002</td>\n",
       "      <td>0.615915</td>\n",
       "      <td>0.620617</td>\n",
       "      <td>0.620617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.526721</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.129965</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>-0.002684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.620617</td>\n",
       "      <td>0.622781</td>\n",
       "      <td>0.616599</td>\n",
       "      <td>0.622394</td>\n",
       "      <td>0.622394</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.549598</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.123905</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-0.004864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>0.704002</td>\n",
       "      <td>0.705430</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.003287</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>-0.002947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>0.676821</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.443293</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>-0.004897</td>\n",
       "      <td>-0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>0.704072</td>\n",
       "      <td>0.709512</td>\n",
       "      <td>0.703700</td>\n",
       "      <td>0.704072</td>\n",
       "      <td>0.704072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.003267</td>\n",
       "      <td>-0.003078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.677012</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.448389</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>-0.004374</td>\n",
       "      <td>-0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>0.701740</td>\n",
       "      <td>0.708421</td>\n",
       "      <td>0.701538</td>\n",
       "      <td>0.701641</td>\n",
       "      <td>0.701641</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002430</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-0.002499</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001699</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.016817</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.445866</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>-0.006233</td>\n",
       "      <td>-0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>0.709280</td>\n",
       "      <td>0.711101</td>\n",
       "      <td>0.707559</td>\n",
       "      <td>0.709401</td>\n",
       "      <td>0.709401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>0.023613</td>\n",
       "      <td>0.702180</td>\n",
       "      <td>-0.000507</td>\n",
       "      <td>0.446968</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.009845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>0.709900</td>\n",
       "      <td>0.712078</td>\n",
       "      <td>0.707769</td>\n",
       "      <td>0.709849</td>\n",
       "      <td>0.709849</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>0.705831</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>0.449194</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>-0.002447</td>\n",
       "      <td>-0.010539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3722 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low     Close  Adj Close  Volume  diff-day-1  \\\n",
       "0     0.621504  0.623791  0.618506  0.619809   0.619809       0   -0.001695   \n",
       "1     0.619617  0.620001  0.614817  0.618582   0.618582       0   -0.001227   \n",
       "2     0.618697  0.620232  0.616105  0.619310   0.619310       0    0.000728   \n",
       "3     0.619195  0.621002  0.615915  0.620617   0.620617       0    0.001307   \n",
       "4     0.620617  0.622781  0.616599  0.622394   0.622394       0    0.001777   \n",
       "...        ...       ...       ...       ...        ...     ...         ...   \n",
       "3717  0.704002  0.705430  0.702500  0.704052   0.704052       0   -0.000088   \n",
       "3718  0.704072  0.709512  0.703700  0.704072   0.704072       0    0.000020   \n",
       "3719  0.701740  0.708421  0.701538  0.701641   0.701641       0   -0.002430   \n",
       "3720  0.709280  0.711101  0.707559  0.709401   0.709401       0    0.007760   \n",
       "3721  0.709900  0.712078  0.707769  0.709849   0.709849       0    0.000448   \n",
       "\n",
       "      diff-day-2  diff-day-3  diff-day-4  ...     EMA-7    EMA-21    EMA-50  \\\n",
       "0      -0.006208   -0.002933   -0.005777  ... -0.002277  0.000298 -0.000909   \n",
       "1      -0.002922   -0.007435   -0.004160  ... -0.002628 -0.000845 -0.002052   \n",
       "2      -0.000499   -0.002194   -0.006707  ... -0.001425 -0.000106 -0.001272   \n",
       "3       0.002035    0.000808   -0.000887  ... -0.000089  0.001091  0.000033   \n",
       "4       0.003084    0.003812    0.002585  ...  0.001266  0.002608  0.001739   \n",
       "...          ...         ...         ...  ...       ...       ...       ...   \n",
       "3717   -0.003287   -0.003098   -0.002947  ...  0.000200  0.008570  0.020727   \n",
       "3718   -0.000068   -0.003267   -0.003078  ...  0.000165  0.007809  0.019934   \n",
       "3719   -0.002411   -0.002499   -0.005697  ... -0.001699  0.004889  0.016817   \n",
       "3720    0.005329    0.005349    0.005261  ...  0.004545  0.011499  0.023613   \n",
       "3721    0.008208    0.005777    0.005797  ...  0.003745  0.010861  0.023117   \n",
       "\n",
       "           RSI      MACD       ADX       STD  bb_width    bb_buy   bb_sell  \n",
       "0     0.515714  0.001007  0.154273  0.002375  0.009498 -0.008072 -0.001426  \n",
       "1     0.500428  0.000573  0.146584  0.002571  0.010285 -0.008291 -0.001994  \n",
       "2     0.509713  0.000313  0.138918  0.002666  0.010664 -0.007066 -0.003597  \n",
       "3     0.526721  0.000212  0.129965  0.001016  0.004063 -0.001379 -0.002684  \n",
       "4     0.549598  0.000245  0.123905  0.001306  0.005225 -0.000361 -0.004864  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3717  0.676821 -0.000012  0.443293  0.001506  0.006025 -0.004897 -0.001129  \n",
       "3718  0.677012 -0.000312  0.448389  0.001548  0.006191 -0.004374 -0.001817  \n",
       "3719  0.627907 -0.000714  0.445866  0.001813  0.007251 -0.006233 -0.001018  \n",
       "3720  0.702180 -0.000507  0.446968  0.002553  0.010210 -0.000365 -0.009845  \n",
       "3721  0.705831 -0.000394  0.449194  0.003247  0.012986 -0.002447 -0.010539  \n",
       "\n",
       "[3722 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = pd.read_csv('./' + ticker + '_input_signals.csv')\n",
    "predictors_list = list(predictors.columns)\n",
    "supporting_predictors = predictors[supporting_predictor_names]\n",
    "predictors = predictors.drop(supporting_predictor_names, axis = 1)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('./' + ticker + '_output_signals.csv')\n",
    "#target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1126bccd0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adj_close = predictors[\"Adj Close\"].to_numpy()[1000:1100]\n",
    "ema = supporting_predictors[\"RAW-EMA-3\"].to_numpy()[1000:1100]\n",
    "\n",
    "plt.plot(adj_close)\n",
    "plt.plot(ema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_predictors, test_predictors, train_targets, test_targets = train_test_split(\n",
    "        predictors,\n",
    "        target,\n",
    "        test_size=0.20,\n",
    "        random_state=42,\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>diff-day-1</th>\n",
       "      <th>diff-day-2</th>\n",
       "      <th>diff-day-3</th>\n",
       "      <th>diff-day-4</th>\n",
       "      <th>...</th>\n",
       "      <th>EMA-7</th>\n",
       "      <th>EMA-21</th>\n",
       "      <th>EMA-50</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ADX</th>\n",
       "      <th>STD</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_buy</th>\n",
       "      <th>bb_sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.621504</td>\n",
       "      <td>0.623791</td>\n",
       "      <td>0.618506</td>\n",
       "      <td>0.619809</td>\n",
       "      <td>0.619809</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001695</td>\n",
       "      <td>-0.006208</td>\n",
       "      <td>-0.002933</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.154273</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>-0.008072</td>\n",
       "      <td>-0.001426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.619617</td>\n",
       "      <td>0.620001</td>\n",
       "      <td>0.614817</td>\n",
       "      <td>0.618582</td>\n",
       "      <td>0.618582</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>-0.002922</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>-0.002052</td>\n",
       "      <td>0.500428</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.146584</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>-0.008291</td>\n",
       "      <td>-0.001994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.618697</td>\n",
       "      <td>0.620232</td>\n",
       "      <td>0.616105</td>\n",
       "      <td>0.619310</td>\n",
       "      <td>0.619310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>-0.006707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.001272</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>-0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.619195</td>\n",
       "      <td>0.621002</td>\n",
       "      <td>0.615915</td>\n",
       "      <td>0.620617</td>\n",
       "      <td>0.620617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.526721</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.129965</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>-0.002684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.620617</td>\n",
       "      <td>0.622781</td>\n",
       "      <td>0.616599</td>\n",
       "      <td>0.622394</td>\n",
       "      <td>0.622394</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.549598</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.123905</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-0.004864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>0.711389</td>\n",
       "      <td>0.721397</td>\n",
       "      <td>0.706115</td>\n",
       "      <td>0.711389</td>\n",
       "      <td>0.711389</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.702257</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>-0.002062</td>\n",
       "      <td>-0.011341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>0.708918</td>\n",
       "      <td>0.713089</td>\n",
       "      <td>0.708898</td>\n",
       "      <td>0.708818</td>\n",
       "      <td>0.708818</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002572</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.649917</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.291316</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.010965</td>\n",
       "      <td>-0.004618</td>\n",
       "      <td>-0.006347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>0.710071</td>\n",
       "      <td>0.711389</td>\n",
       "      <td>0.707469</td>\n",
       "      <td>0.710021</td>\n",
       "      <td>0.710021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>-0.001369</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.662584</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.306916</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.715129</td>\n",
       "      <td>0.707569</td>\n",
       "      <td>0.709019</td>\n",
       "      <td>0.709019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.641756</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.324997</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>-0.001162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>0.715922</td>\n",
       "      <td>0.718752</td>\n",
       "      <td>0.714628</td>\n",
       "      <td>0.715599</td>\n",
       "      <td>0.715599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.706926</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.009606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2977 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low     Close  Adj Close  Volume  diff-day-1  \\\n",
       "0     0.621504  0.623791  0.618506  0.619809   0.619809       0   -0.001695   \n",
       "1     0.619617  0.620001  0.614817  0.618582   0.618582       0   -0.001227   \n",
       "2     0.618697  0.620232  0.616105  0.619310   0.619310       0    0.000728   \n",
       "3     0.619195  0.621002  0.615915  0.620617   0.620617       0    0.001307   \n",
       "4     0.620617  0.622781  0.616599  0.622394   0.622394       0    0.001777   \n",
       "...        ...       ...       ...       ...        ...     ...         ...   \n",
       "2972  0.711389  0.721397  0.706115  0.711389   0.711389       0    0.002049   \n",
       "2973  0.708918  0.713089  0.708898  0.708818   0.708818       0   -0.002572   \n",
       "2974  0.710071  0.711389  0.707469  0.710021   0.710021       0    0.001203   \n",
       "2975  0.708848  0.715129  0.707569  0.709019   0.709019       0   -0.001002   \n",
       "2976  0.715922  0.718752  0.714628  0.715599   0.715599       0    0.006581   \n",
       "\n",
       "      diff-day-2  diff-day-3  diff-day-4  ...     EMA-7    EMA-21    EMA-50  \\\n",
       "0      -0.006208   -0.002933   -0.005777  ... -0.002277  0.000298 -0.000909   \n",
       "1      -0.002922   -0.007435   -0.004160  ... -0.002628 -0.000845 -0.002052   \n",
       "2      -0.000499   -0.002194   -0.006707  ... -0.001425 -0.000106 -0.001272   \n",
       "3       0.002035    0.000808   -0.000887  ... -0.000089  0.001091  0.000033   \n",
       "4       0.003084    0.003812    0.002585  ...  0.001266  0.002608  0.001739   \n",
       "...          ...         ...         ...  ...       ...       ...       ...   \n",
       "2972    0.004421    0.008140    0.008589  ...  0.005383  0.011778  0.012642   \n",
       "2973   -0.000523    0.001849    0.005568  ...  0.002108  0.008369  0.009676   \n",
       "2974   -0.001369    0.000680    0.003052  ...  0.002483  0.008702  0.010452   \n",
       "2975    0.000201   -0.002371   -0.000322  ...  0.001111  0.007000  0.009080   \n",
       "2976    0.005579    0.006782    0.004210  ...  0.005769  0.012346  0.015046   \n",
       "\n",
       "           RSI      MACD       ADX       STD  bb_width    bb_buy   bb_sell  \n",
       "0     0.515714  0.001007  0.154273  0.002375  0.009498 -0.008072 -0.001426  \n",
       "1     0.500428  0.000573  0.146584  0.002571  0.010285 -0.008291 -0.001994  \n",
       "2     0.509713  0.000313  0.138918  0.002666  0.010664 -0.007066 -0.003597  \n",
       "3     0.526721  0.000212  0.129965  0.001016  0.004063 -0.001379 -0.002684  \n",
       "4     0.549598  0.000245  0.123905  0.001306  0.005225 -0.000361 -0.004864  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2972  0.702257  0.001591  0.269600  0.003351  0.013403 -0.002062 -0.011341  \n",
       "2973  0.649917  0.001377  0.291316  0.002741  0.010965 -0.004618 -0.006347  \n",
       "2974  0.662584  0.001218  0.306916  0.001453  0.005811 -0.002193 -0.003619  \n",
       "2975  0.641756  0.000959  0.324997  0.000930  0.003721 -0.002559 -0.001162  \n",
       "2976  0.706926  0.001133  0.344828  0.002488  0.009952 -0.000346 -0.009606  \n",
       "\n",
       "[2977 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### More Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_targets = np.ravel(train_targets)\n",
    "test_targets = np.ravel(test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 3 - Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Validation Split\n",
    "the_train_predictors, test_validation_predictors, the_train_targets, test_validation_targets = train_test_split(\n",
    "        train_predictors,\n",
    "        train_targets,\n",
    "        test_size=0.20,\n",
    "        random_state=42,\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Features : \" + str(train_predictors.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(100, activation='relu', input_shape=(train_predictors.shape[1],)))\n",
    "model.add(layers.Dense(80, activation='relu', input_shape=(train_predictors.shape[1],)))\n",
    "model.add(layers.Dense(60, activation='relu', input_shape=(train_predictors.shape[1],)))\n",
    "model.add(layers.Dense(30, activation='relu', input_shape=(train_predictors.shape[1],)))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 3s 152ms/step - loss: 0.6245 - accuracy: 0.9006 - val_loss: 0.4707 - val_accuracy: 0.9027\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4214 - accuracy: 0.9141 - val_loss: 0.3444 - val_accuracy: 0.9027\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3174 - accuracy: 0.9106 - val_loss: 0.3129 - val_accuracy: 0.9027\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3049 - accuracy: 0.9062 - val_loss: 0.3100 - val_accuracy: 0.9027\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3012 - accuracy: 0.9069 - val_loss: 0.3092 - val_accuracy: 0.9027\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2913 - accuracy: 0.9116 - val_loss: 0.3104 - val_accuracy: 0.9027\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3043 - accuracy: 0.9048 - val_loss: 0.3072 - val_accuracy: 0.9027\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2896 - accuracy: 0.9111 - val_loss: 0.3150 - val_accuracy: 0.9027\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2962 - accuracy: 0.9098 - val_loss: 0.3112 - val_accuracy: 0.9027\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3032 - accuracy: 0.9040 - val_loss: 0.3040 - val_accuracy: 0.9027\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2888 - accuracy: 0.9111 - val_loss: 0.3037 - val_accuracy: 0.9027\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2829 - accuracy: 0.9121 - val_loss: 0.3022 - val_accuracy: 0.9027\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2956 - accuracy: 0.9062 - val_loss: 0.3000 - val_accuracy: 0.9027\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3009 - accuracy: 0.9045 - val_loss: 0.3003 - val_accuracy: 0.9027\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2868 - accuracy: 0.9092 - val_loss: 0.2985 - val_accuracy: 0.9027\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2947 - accuracy: 0.9046 - val_loss: 0.2995 - val_accuracy: 0.9027\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2906 - accuracy: 0.9062 - val_loss: 0.2937 - val_accuracy: 0.9027\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2886 - accuracy: 0.9060 - val_loss: 0.2916 - val_accuracy: 0.9027\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2842 - accuracy: 0.9088 - val_loss: 0.2923 - val_accuracy: 0.9027\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2973 - accuracy: 0.8999 - val_loss: 0.2890 - val_accuracy: 0.9027\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    the_train_predictors,\n",
    "    the_train_targets,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(test_validation_predictors, test_validation_targets)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.9074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2801100015640259, 0.9073825478553772]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(test_predictors, test_targets)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.34808853], dtype=float32),\n",
       " array([0.32413635], dtype=float32),\n",
       " array([0.3140135], dtype=float32),\n",
       " array([0.2612541], dtype=float32),\n",
       " array([0.25056547], dtype=float32),\n",
       " array([0.23200414], dtype=float32),\n",
       " array([0.22832936], dtype=float32),\n",
       " array([0.1955702], dtype=float32),\n",
       " array([0.19173172], dtype=float32),\n",
       " array([0.18994185], dtype=float32),\n",
       " array([0.18863061], dtype=float32),\n",
       " array([0.1878103], dtype=float32),\n",
       " array([0.18675217], dtype=float32),\n",
       " array([0.18589312], dtype=float32),\n",
       " array([0.18474633], dtype=float32),\n",
       " array([0.18463695], dtype=float32),\n",
       " array([0.18375471], dtype=float32),\n",
       " array([0.18180522], dtype=float32),\n",
       " array([0.18139929], dtype=float32),\n",
       " array([0.1813778], dtype=float32),\n",
       " array([0.1806412], dtype=float32),\n",
       " array([0.17881864], dtype=float32),\n",
       " array([0.17859736], dtype=float32),\n",
       " array([0.17842361], dtype=float32),\n",
       " array([0.17811859], dtype=float32),\n",
       " array([0.17558575], dtype=float32),\n",
       " array([0.17491826], dtype=float32),\n",
       " array([0.17420647], dtype=float32),\n",
       " array([0.17279908], dtype=float32),\n",
       " array([0.17031193], dtype=float32),\n",
       " array([0.16936666], dtype=float32),\n",
       " array([0.1685392], dtype=float32),\n",
       " array([0.16819611], dtype=float32),\n",
       " array([0.16803595], dtype=float32),\n",
       " array([0.1678617], dtype=float32),\n",
       " array([0.16760236], dtype=float32),\n",
       " array([0.16707766], dtype=float32),\n",
       " array([0.16549328], dtype=float32),\n",
       " array([0.16355515], dtype=float32),\n",
       " array([0.16087434], dtype=float32),\n",
       " array([0.16062662], dtype=float32),\n",
       " array([0.159866], dtype=float32),\n",
       " array([0.1589494], dtype=float32),\n",
       " array([0.15804505], dtype=float32),\n",
       " array([0.15684304], dtype=float32),\n",
       " array([0.1566351], dtype=float32),\n",
       " array([0.15644228], dtype=float32),\n",
       " array([0.15570736], dtype=float32),\n",
       " array([0.15528503], dtype=float32),\n",
       " array([0.15486118], dtype=float32),\n",
       " array([0.15480462], dtype=float32),\n",
       " array([0.1545676], dtype=float32),\n",
       " array([0.15337896], dtype=float32),\n",
       " array([0.15272462], dtype=float32),\n",
       " array([0.151768], dtype=float32),\n",
       " array([0.15124822], dtype=float32),\n",
       " array([0.15008816], dtype=float32),\n",
       " array([0.14876154], dtype=float32),\n",
       " array([0.14795527], dtype=float32),\n",
       " array([0.14722183], dtype=float32),\n",
       " array([0.14509189], dtype=float32),\n",
       " array([0.14504018], dtype=float32),\n",
       " array([0.14488515], dtype=float32),\n",
       " array([0.14478582], dtype=float32),\n",
       " array([0.14443567], dtype=float32),\n",
       " array([0.14383304], dtype=float32),\n",
       " array([0.1429064], dtype=float32),\n",
       " array([0.14209285], dtype=float32),\n",
       " array([0.14153045], dtype=float32),\n",
       " array([0.14128381], dtype=float32),\n",
       " array([0.14104086], dtype=float32),\n",
       " array([0.14065492], dtype=float32),\n",
       " array([0.14033493], dtype=float32),\n",
       " array([0.14009073], dtype=float32),\n",
       " array([0.13995484], dtype=float32),\n",
       " array([0.13942224], dtype=float32),\n",
       " array([0.13843995], dtype=float32),\n",
       " array([0.13804406], dtype=float32),\n",
       " array([0.13738284], dtype=float32),\n",
       " array([0.13704082], dtype=float32),\n",
       " array([0.1359911], dtype=float32),\n",
       " array([0.13580689], dtype=float32),\n",
       " array([0.13543004], dtype=float32),\n",
       " array([0.13452962], dtype=float32),\n",
       " array([0.13404387], dtype=float32),\n",
       " array([0.13364762], dtype=float32),\n",
       " array([0.1334041], dtype=float32),\n",
       " array([0.13310826], dtype=float32),\n",
       " array([0.13302892], dtype=float32),\n",
       " array([0.13288316], dtype=float32),\n",
       " array([0.13263145], dtype=float32),\n",
       " array([0.13240388], dtype=float32),\n",
       " array([0.13236412], dtype=float32),\n",
       " array([0.13211265], dtype=float32),\n",
       " array([0.1318908], dtype=float32),\n",
       " array([0.13165581], dtype=float32),\n",
       " array([0.13164216], dtype=float32),\n",
       " array([0.13119453], dtype=float32),\n",
       " array([0.13086593], dtype=float32),\n",
       " array([0.13084874], dtype=float32),\n",
       " array([0.13040304], dtype=float32),\n",
       " array([0.13030785], dtype=float32),\n",
       " array([0.13022605], dtype=float32),\n",
       " array([0.13019708], dtype=float32),\n",
       " array([0.1296964], dtype=float32),\n",
       " array([0.12919855], dtype=float32),\n",
       " array([0.12902743], dtype=float32),\n",
       " array([0.12896577], dtype=float32),\n",
       " array([0.12853453], dtype=float32),\n",
       " array([0.12840235], dtype=float32),\n",
       " array([0.1281671], dtype=float32),\n",
       " array([0.12749231], dtype=float32),\n",
       " array([0.12734818], dtype=float32),\n",
       " array([0.12733522], dtype=float32),\n",
       " array([0.12662005], dtype=float32),\n",
       " array([0.12653676], dtype=float32),\n",
       " array([0.1256442], dtype=float32),\n",
       " array([0.12512937], dtype=float32),\n",
       " array([0.12500864], dtype=float32),\n",
       " array([0.12486652], dtype=float32),\n",
       " array([0.12476882], dtype=float32),\n",
       " array([0.12473133], dtype=float32),\n",
       " array([0.12459761], dtype=float32),\n",
       " array([0.1242249], dtype=float32),\n",
       " array([0.12418327], dtype=float32),\n",
       " array([0.12404284], dtype=float32),\n",
       " array([0.12322253], dtype=float32),\n",
       " array([0.12321043], dtype=float32),\n",
       " array([0.12236547], dtype=float32),\n",
       " array([0.12210631], dtype=float32),\n",
       " array([0.12194231], dtype=float32),\n",
       " array([0.12175271], dtype=float32),\n",
       " array([0.12135223], dtype=float32),\n",
       " array([0.12119216], dtype=float32),\n",
       " array([0.12079409], dtype=float32),\n",
       " array([0.12077484], dtype=float32),\n",
       " array([0.12049395], dtype=float32),\n",
       " array([0.12038791], dtype=float32),\n",
       " array([0.1203343], dtype=float32),\n",
       " array([0.12013572], dtype=float32),\n",
       " array([0.12008825], dtype=float32),\n",
       " array([0.1196537], dtype=float32),\n",
       " array([0.11960709], dtype=float32),\n",
       " array([0.11948493], dtype=float32),\n",
       " array([0.11895031], dtype=float32),\n",
       " array([0.11874789], dtype=float32),\n",
       " array([0.11861968], dtype=float32),\n",
       " array([0.11855084], dtype=float32),\n",
       " array([0.11843461], dtype=float32),\n",
       " array([0.11832947], dtype=float32),\n",
       " array([0.11829227], dtype=float32),\n",
       " array([0.11817822], dtype=float32),\n",
       " array([0.11815545], dtype=float32),\n",
       " array([0.11792603], dtype=float32),\n",
       " array([0.11755157], dtype=float32),\n",
       " array([0.11744159], dtype=float32),\n",
       " array([0.11729524], dtype=float32),\n",
       " array([0.1164923], dtype=float32),\n",
       " array([0.11580795], dtype=float32),\n",
       " array([0.11510292], dtype=float32),\n",
       " array([0.11449775], dtype=float32),\n",
       " array([0.11441779], dtype=float32),\n",
       " array([0.11417484], dtype=float32),\n",
       " array([0.11392936], dtype=float32),\n",
       " array([0.11388287], dtype=float32),\n",
       " array([0.11337855], dtype=float32),\n",
       " array([0.11334479], dtype=float32),\n",
       " array([0.11299571], dtype=float32),\n",
       " array([0.11279491], dtype=float32),\n",
       " array([0.11252367], dtype=float32),\n",
       " array([0.11221331], dtype=float32),\n",
       " array([0.11136836], dtype=float32),\n",
       " array([0.11129466], dtype=float32),\n",
       " array([0.111229], dtype=float32),\n",
       " array([0.11119863], dtype=float32),\n",
       " array([0.1111781], dtype=float32),\n",
       " array([0.1111553], dtype=float32),\n",
       " array([0.1108219], dtype=float32),\n",
       " array([0.11081192], dtype=float32),\n",
       " array([0.11053205], dtype=float32),\n",
       " array([0.11051646], dtype=float32),\n",
       " array([0.11050394], dtype=float32),\n",
       " array([0.11026734], dtype=float32),\n",
       " array([0.11026439], dtype=float32),\n",
       " array([0.10991743], dtype=float32),\n",
       " array([0.10979468], dtype=float32),\n",
       " array([0.10974565], dtype=float32),\n",
       " array([0.10955021], dtype=float32),\n",
       " array([0.10953897], dtype=float32),\n",
       " array([0.10931402], dtype=float32),\n",
       " array([0.10917836], dtype=float32),\n",
       " array([0.10885629], dtype=float32),\n",
       " array([0.10880199], dtype=float32),\n",
       " array([0.10809499], dtype=float32),\n",
       " array([0.10805705], dtype=float32),\n",
       " array([0.10788506], dtype=float32),\n",
       " array([0.10768315], dtype=float32),\n",
       " array([0.10767639], dtype=float32),\n",
       " array([0.10763747], dtype=float32),\n",
       " array([0.10747743], dtype=float32),\n",
       " array([0.10747418], dtype=float32),\n",
       " array([0.10745481], dtype=float32),\n",
       " array([0.10719043], dtype=float32),\n",
       " array([0.10717881], dtype=float32),\n",
       " array([0.10712057], dtype=float32),\n",
       " array([0.10701865], dtype=float32),\n",
       " array([0.10678527], dtype=float32),\n",
       " array([0.10639578], dtype=float32),\n",
       " array([0.10633129], dtype=float32),\n",
       " array([0.10611606], dtype=float32),\n",
       " array([0.10588118], dtype=float32),\n",
       " array([0.10585111], dtype=float32),\n",
       " array([0.10562956], dtype=float32),\n",
       " array([0.1051625], dtype=float32),\n",
       " array([0.10457689], dtype=float32),\n",
       " array([0.10448709], dtype=float32),\n",
       " array([0.10443091], dtype=float32),\n",
       " array([0.10438877], dtype=float32),\n",
       " array([0.104123], dtype=float32),\n",
       " array([0.10389426], dtype=float32),\n",
       " array([0.10278881], dtype=float32),\n",
       " array([0.10261807], dtype=float32),\n",
       " array([0.1025486], dtype=float32),\n",
       " array([0.10246244], dtype=float32),\n",
       " array([0.10224694], dtype=float32),\n",
       " array([0.1019595], dtype=float32),\n",
       " array([0.10178775], dtype=float32),\n",
       " array([0.10164133], dtype=float32),\n",
       " array([0.10157999], dtype=float32),\n",
       " array([0.10130593], dtype=float32),\n",
       " array([0.1012654], dtype=float32),\n",
       " array([0.10102826], dtype=float32),\n",
       " array([0.10088223], dtype=float32),\n",
       " array([0.10079798], dtype=float32),\n",
       " array([0.10021916], dtype=float32),\n",
       " array([0.10006398], dtype=float32),\n",
       " array([0.09951332], dtype=float32),\n",
       " array([0.09908682], dtype=float32),\n",
       " array([0.09906825], dtype=float32),\n",
       " array([0.09897342], dtype=float32),\n",
       " array([0.09895808], dtype=float32),\n",
       " array([0.09885132], dtype=float32),\n",
       " array([0.0988093], dtype=float32),\n",
       " array([0.09870169], dtype=float32),\n",
       " array([0.09839389], dtype=float32),\n",
       " array([0.09809303], dtype=float32),\n",
       " array([0.09805888], dtype=float32),\n",
       " array([0.09785229], dtype=float32),\n",
       " array([0.09767354], dtype=float32),\n",
       " array([0.09731111], dtype=float32),\n",
       " array([0.09723201], dtype=float32),\n",
       " array([0.09717888], dtype=float32),\n",
       " array([0.0969606], dtype=float32),\n",
       " array([0.0969075], dtype=float32),\n",
       " array([0.096609], dtype=float32),\n",
       " array([0.09636414], dtype=float32),\n",
       " array([0.09611726], dtype=float32),\n",
       " array([0.09590974], dtype=float32),\n",
       " array([0.09582275], dtype=float32),\n",
       " array([0.09526196], dtype=float32),\n",
       " array([0.09523097], dtype=float32),\n",
       " array([0.09521785], dtype=float32),\n",
       " array([0.09517109], dtype=float32),\n",
       " array([0.09478572], dtype=float32),\n",
       " array([0.09462291], dtype=float32),\n",
       " array([0.0945833], dtype=float32),\n",
       " array([0.09452364], dtype=float32),\n",
       " array([0.09446877], dtype=float32),\n",
       " array([0.09429511], dtype=float32),\n",
       " array([0.09419957], dtype=float32),\n",
       " array([0.09377348], dtype=float32),\n",
       " array([0.0936968], dtype=float32),\n",
       " array([0.09363952], dtype=float32),\n",
       " array([0.09357852], dtype=float32),\n",
       " array([0.09337777], dtype=float32),\n",
       " array([0.09315836], dtype=float32),\n",
       " array([0.0930647], dtype=float32),\n",
       " array([0.09274161], dtype=float32),\n",
       " array([0.09263936], dtype=float32),\n",
       " array([0.09246609], dtype=float32),\n",
       " array([0.09215868], dtype=float32),\n",
       " array([0.0920628], dtype=float32),\n",
       " array([0.09182644], dtype=float32),\n",
       " array([0.09174007], dtype=float32),\n",
       " array([0.09171104], dtype=float32),\n",
       " array([0.09143996], dtype=float32),\n",
       " array([0.09142196], dtype=float32),\n",
       " array([0.09100387], dtype=float32),\n",
       " array([0.09089592], dtype=float32),\n",
       " array([0.09058461], dtype=float32),\n",
       " array([0.09052992], dtype=float32),\n",
       " array([0.0904358], dtype=float32),\n",
       " array([0.09041873], dtype=float32),\n",
       " array([0.09028217], dtype=float32),\n",
       " array([0.09020936], dtype=float32),\n",
       " array([0.08988845], dtype=float32),\n",
       " array([0.08968785], dtype=float32),\n",
       " array([0.08961308], dtype=float32),\n",
       " array([0.08949941], dtype=float32),\n",
       " array([0.08934218], dtype=float32),\n",
       " array([0.08913603], dtype=float32),\n",
       " array([0.08913177], dtype=float32),\n",
       " array([0.08874863], dtype=float32),\n",
       " array([0.08843631], dtype=float32),\n",
       " array([0.08839133], dtype=float32),\n",
       " array([0.08836156], dtype=float32),\n",
       " array([0.08805695], dtype=float32),\n",
       " array([0.08782068], dtype=float32),\n",
       " array([0.0875918], dtype=float32),\n",
       " array([0.08728069], dtype=float32),\n",
       " array([0.08726138], dtype=float32),\n",
       " array([0.08723539], dtype=float32),\n",
       " array([0.08707973], dtype=float32),\n",
       " array([0.08707625], dtype=float32),\n",
       " array([0.08694854], dtype=float32),\n",
       " array([0.08690384], dtype=float32),\n",
       " array([0.08684731], dtype=float32),\n",
       " array([0.08667159], dtype=float32),\n",
       " array([0.08639202], dtype=float32),\n",
       " array([0.08627003], dtype=float32),\n",
       " array([0.08619168], dtype=float32),\n",
       " array([0.08593899], dtype=float32),\n",
       " array([0.08589947], dtype=float32),\n",
       " array([0.08559495], dtype=float32),\n",
       " array([0.08549526], dtype=float32),\n",
       " array([0.08549407], dtype=float32),\n",
       " array([0.08529985], dtype=float32),\n",
       " array([0.08518064], dtype=float32),\n",
       " array([0.08509547], dtype=float32),\n",
       " array([0.08503124], dtype=float32),\n",
       " array([0.08464584], dtype=float32),\n",
       " array([0.08457792], dtype=float32),\n",
       " array([0.08452988], dtype=float32),\n",
       " array([0.08447218], dtype=float32),\n",
       " array([0.08446527], dtype=float32),\n",
       " array([0.08425307], dtype=float32),\n",
       " array([0.08421597], dtype=float32),\n",
       " array([0.08364117], dtype=float32),\n",
       " array([0.08353859], dtype=float32),\n",
       " array([0.0835197], dtype=float32),\n",
       " array([0.08334434], dtype=float32),\n",
       " array([0.08318913], dtype=float32),\n",
       " array([0.08316195], dtype=float32),\n",
       " array([0.08303994], dtype=float32),\n",
       " array([0.08303869], dtype=float32),\n",
       " array([0.08299768], dtype=float32),\n",
       " array([0.08291361], dtype=float32),\n",
       " array([0.08259472], dtype=float32),\n",
       " array([0.08207837], dtype=float32),\n",
       " array([0.08197081], dtype=float32),\n",
       " array([0.08187801], dtype=float32),\n",
       " array([0.08159184], dtype=float32),\n",
       " array([0.08147123], dtype=float32),\n",
       " array([0.08085501], dtype=float32),\n",
       " array([0.08063239], dtype=float32),\n",
       " array([0.08054957], dtype=float32),\n",
       " array([0.08050612], dtype=float32),\n",
       " array([0.08007962], dtype=float32),\n",
       " array([0.07974151], dtype=float32),\n",
       " array([0.07972792], dtype=float32),\n",
       " array([0.07936108], dtype=float32),\n",
       " array([0.07926658], dtype=float32),\n",
       " array([0.07854545], dtype=float32),\n",
       " array([0.07828462], dtype=float32),\n",
       " array([0.07809532], dtype=float32),\n",
       " array([0.0779869], dtype=float32),\n",
       " array([0.07746527], dtype=float32),\n",
       " array([0.0774186], dtype=float32),\n",
       " array([0.07703874], dtype=float32),\n",
       " array([0.07674807], dtype=float32),\n",
       " array([0.07670796], dtype=float32),\n",
       " array([0.07657793], dtype=float32),\n",
       " array([0.07653278], dtype=float32),\n",
       " array([0.07630467], dtype=float32),\n",
       " array([0.07608366], dtype=float32),\n",
       " array([0.07602832], dtype=float32),\n",
       " array([0.07590878], dtype=float32),\n",
       " array([0.07540566], dtype=float32),\n",
       " array([0.07528764], dtype=float32),\n",
       " array([0.07525307], dtype=float32),\n",
       " array([0.07524857], dtype=float32),\n",
       " array([0.07521918], dtype=float32),\n",
       " array([0.07499862], dtype=float32),\n",
       " array([0.07493055], dtype=float32),\n",
       " array([0.07487729], dtype=float32),\n",
       " array([0.0748629], dtype=float32),\n",
       " array([0.07481617], dtype=float32),\n",
       " array([0.07478657], dtype=float32),\n",
       " array([0.07473224], dtype=float32),\n",
       " array([0.07467452], dtype=float32),\n",
       " array([0.07462952], dtype=float32),\n",
       " array([0.07424405], dtype=float32),\n",
       " array([0.07417506], dtype=float32),\n",
       " array([0.07416528], dtype=float32),\n",
       " array([0.07404226], dtype=float32),\n",
       " array([0.07370839], dtype=float32),\n",
       " array([0.0736106], dtype=float32),\n",
       " array([0.07346928], dtype=float32),\n",
       " array([0.07341841], dtype=float32),\n",
       " array([0.07318336], dtype=float32),\n",
       " array([0.07300854], dtype=float32),\n",
       " array([0.07264191], dtype=float32),\n",
       " array([0.07248086], dtype=float32),\n",
       " array([0.07222795], dtype=float32),\n",
       " array([0.07195723], dtype=float32),\n",
       " array([0.07193819], dtype=float32),\n",
       " array([0.07164517], dtype=float32),\n",
       " array([0.07156679], dtype=float32),\n",
       " array([0.07156241], dtype=float32),\n",
       " array([0.07131115], dtype=float32),\n",
       " array([0.07128608], dtype=float32),\n",
       " array([0.07122979], dtype=float32),\n",
       " array([0.07103798], dtype=float32),\n",
       " array([0.07099298], dtype=float32),\n",
       " array([0.07082006], dtype=float32),\n",
       " array([0.07037416], dtype=float32),\n",
       " array([0.07006675], dtype=float32),\n",
       " array([0.07000503], dtype=float32),\n",
       " array([0.06992999], dtype=float32),\n",
       " array([0.06990799], dtype=float32),\n",
       " array([0.06978834], dtype=float32),\n",
       " array([0.06965882], dtype=float32),\n",
       " array([0.06951755], dtype=float32),\n",
       " array([0.06875047], dtype=float32),\n",
       " array([0.06861958], dtype=float32),\n",
       " array([0.06860435], dtype=float32),\n",
       " array([0.06847736], dtype=float32),\n",
       " array([0.06822923], dtype=float32),\n",
       " array([0.06795317], dtype=float32),\n",
       " array([0.06792933], dtype=float32),\n",
       " array([0.06786206], dtype=float32),\n",
       " array([0.06773767], dtype=float32),\n",
       " array([0.0676645], dtype=float32),\n",
       " array([0.06761137], dtype=float32),\n",
       " array([0.06727993], dtype=float32),\n",
       " array([0.06715891], dtype=float32),\n",
       " array([0.06706318], dtype=float32),\n",
       " array([0.06695166], dtype=float32),\n",
       " array([0.06691557], dtype=float32),\n",
       " array([0.06677905], dtype=float32),\n",
       " array([0.0666872], dtype=float32),\n",
       " array([0.0664455], dtype=float32),\n",
       " array([0.06642938], dtype=float32),\n",
       " array([0.0662818], dtype=float32),\n",
       " array([0.06614372], dtype=float32),\n",
       " array([0.0660671], dtype=float32),\n",
       " array([0.06593165], dtype=float32),\n",
       " array([0.06559342], dtype=float32),\n",
       " array([0.06556472], dtype=float32),\n",
       " array([0.06549218], dtype=float32),\n",
       " array([0.06544003], dtype=float32),\n",
       " array([0.06543988], dtype=float32),\n",
       " array([0.06523055], dtype=float32),\n",
       " array([0.06516817], dtype=float32),\n",
       " array([0.06508231], dtype=float32),\n",
       " array([0.06494009], dtype=float32),\n",
       " array([0.06493336], dtype=float32),\n",
       " array([0.06485862], dtype=float32),\n",
       " array([0.06475124], dtype=float32),\n",
       " array([0.06459716], dtype=float32),\n",
       " array([0.06453744], dtype=float32),\n",
       " array([0.06453401], dtype=float32),\n",
       " array([0.06437793], dtype=float32),\n",
       " array([0.06431749], dtype=float32),\n",
       " array([0.06415373], dtype=float32),\n",
       " array([0.06404874], dtype=float32),\n",
       " array([0.06403604], dtype=float32),\n",
       " array([0.06400436], dtype=float32),\n",
       " array([0.06363764], dtype=float32),\n",
       " array([0.06354758], dtype=float32),\n",
       " array([0.06350046], dtype=float32),\n",
       " array([0.06332844], dtype=float32),\n",
       " array([0.06327546], dtype=float32),\n",
       " array([0.06321976], dtype=float32),\n",
       " array([0.06314659], dtype=float32),\n",
       " array([0.06305602], dtype=float32),\n",
       " array([0.06304798], dtype=float32),\n",
       " array([0.06302202], dtype=float32),\n",
       " array([0.06263891], dtype=float32),\n",
       " array([0.06260088], dtype=float32),\n",
       " array([0.06240392], dtype=float32),\n",
       " array([0.06235579], dtype=float32),\n",
       " array([0.06180409], dtype=float32),\n",
       " array([0.06177241], dtype=float32),\n",
       " array([0.06172809], dtype=float32),\n",
       " array([0.06152588], dtype=float32),\n",
       " array([0.06144619], dtype=float32),\n",
       " array([0.06111136], dtype=float32),\n",
       " array([0.06106138], dtype=float32),\n",
       " array([0.06098831], dtype=float32),\n",
       " array([0.06098759], dtype=float32),\n",
       " array([0.06082928], dtype=float32),\n",
       " array([0.06074786], dtype=float32),\n",
       " array([0.06054345], dtype=float32),\n",
       " array([0.06031412], dtype=float32),\n",
       " array([0.06029344], dtype=float32),\n",
       " array([0.06028265], dtype=float32),\n",
       " array([0.06003174], dtype=float32),\n",
       " array([0.05999798], dtype=float32),\n",
       " array([0.05979714], dtype=float32),\n",
       " array([0.05972022], dtype=float32),\n",
       " array([0.05960301], dtype=float32),\n",
       " array([0.05931434], dtype=float32),\n",
       " array([0.05908558], dtype=float32),\n",
       " array([0.05866539], dtype=float32),\n",
       " array([0.05854934], dtype=float32),\n",
       " array([0.05847865], dtype=float32),\n",
       " array([0.05834359], dtype=float32),\n",
       " array([0.05833751], dtype=float32),\n",
       " array([0.05818376], dtype=float32),\n",
       " array([0.05817965], dtype=float32),\n",
       " array([0.05796909], dtype=float32),\n",
       " array([0.05780095], dtype=float32),\n",
       " array([0.05757853], dtype=float32),\n",
       " array([0.05734712], dtype=float32),\n",
       " array([0.05731058], dtype=float32),\n",
       " array([0.0572052], dtype=float32),\n",
       " array([0.05703825], dtype=float32),\n",
       " array([0.05696312], dtype=float32),\n",
       " array([0.05695957], dtype=float32),\n",
       " array([0.0568561], dtype=float32),\n",
       " array([0.05669132], dtype=float32),\n",
       " array([0.05666295], dtype=float32),\n",
       " array([0.05663106], dtype=float32),\n",
       " array([0.05660316], dtype=float32),\n",
       " array([0.05658263], dtype=float32),\n",
       " array([0.05653763], dtype=float32),\n",
       " array([0.05653033], dtype=float32),\n",
       " array([0.05648276], dtype=float32),\n",
       " array([0.05637822], dtype=float32),\n",
       " array([0.05630207], dtype=float32),\n",
       " array([0.05600029], dtype=float32),\n",
       " array([0.05581406], dtype=float32),\n",
       " array([0.05580419], dtype=float32),\n",
       " array([0.05578652], dtype=float32),\n",
       " array([0.05565375], dtype=float32),\n",
       " array([0.05556375], dtype=float32),\n",
       " array([0.05553448], dtype=float32),\n",
       " array([0.05536523], dtype=float32),\n",
       " array([0.05486852], dtype=float32),\n",
       " array([0.05486497], dtype=float32),\n",
       " array([0.0548107], dtype=float32),\n",
       " array([0.05469108], dtype=float32),\n",
       " array([0.05468538], dtype=float32),\n",
       " array([0.05460048], dtype=float32),\n",
       " array([0.05455586], dtype=float32),\n",
       " array([0.05448747], dtype=float32),\n",
       " array([0.05441397], dtype=float32),\n",
       " array([0.05430269], dtype=float32),\n",
       " array([0.05415705], dtype=float32),\n",
       " array([0.05413711], dtype=float32),\n",
       " array([0.05410603], dtype=float32),\n",
       " array([0.05398917], dtype=float32),\n",
       " array([0.05397931], dtype=float32),\n",
       " array([0.05391371], dtype=float32),\n",
       " array([0.05374897], dtype=float32),\n",
       " array([0.05362293], dtype=float32),\n",
       " array([0.05350611], dtype=float32),\n",
       " array([0.05277044], dtype=float32),\n",
       " array([0.05256796], dtype=float32),\n",
       " array([0.05255997], dtype=float32),\n",
       " array([0.05241928], dtype=float32),\n",
       " array([0.05234075], dtype=float32),\n",
       " array([0.05231267], dtype=float32),\n",
       " array([0.05218017], dtype=float32),\n",
       " array([0.05196992], dtype=float32),\n",
       " array([0.05193222], dtype=float32),\n",
       " array([0.05188152], dtype=float32),\n",
       " array([0.05187079], dtype=float32),\n",
       " array([0.05166909], dtype=float32),\n",
       " array([0.05165878], dtype=float32),\n",
       " array([0.05163908], dtype=float32),\n",
       " array([0.05151591], dtype=float32),\n",
       " array([0.05145508], dtype=float32),\n",
       " array([0.05141434], dtype=float32),\n",
       " array([0.05139536], dtype=float32),\n",
       " array([0.05105352], dtype=float32),\n",
       " array([0.05102542], dtype=float32),\n",
       " array([0.05074745], dtype=float32),\n",
       " array([0.05045301], dtype=float32),\n",
       " array([0.05035466], dtype=float32),\n",
       " array([0.0503068], dtype=float32),\n",
       " array([0.0501664], dtype=float32),\n",
       " array([0.05016381], dtype=float32),\n",
       " array([0.04926065], dtype=float32),\n",
       " array([0.04917756], dtype=float32),\n",
       " array([0.0491395], dtype=float32),\n",
       " array([0.04900557], dtype=float32),\n",
       " array([0.04898879], dtype=float32),\n",
       " array([0.04894942], dtype=float32),\n",
       " array([0.04887253], dtype=float32),\n",
       " array([0.0488475], dtype=float32),\n",
       " array([0.04837632], dtype=float32),\n",
       " array([0.04833886], dtype=float32),\n",
       " array([0.04832879], dtype=float32),\n",
       " array([0.04832086], dtype=float32),\n",
       " array([0.04809234], dtype=float32),\n",
       " array([0.04804105], dtype=float32),\n",
       " array([0.04780567], dtype=float32),\n",
       " array([0.04716343], dtype=float32),\n",
       " array([0.04703721], dtype=float32),\n",
       " array([0.04700771], dtype=float32),\n",
       " array([0.04685882], dtype=float32),\n",
       " array([0.04669851], dtype=float32),\n",
       " array([0.04669413], dtype=float32),\n",
       " array([0.04657504], dtype=float32),\n",
       " array([0.04652265], dtype=float32),\n",
       " array([0.04606101], dtype=float32),\n",
       " array([0.04593527], dtype=float32),\n",
       " array([0.04561916], dtype=float32),\n",
       " array([0.04542026], dtype=float32),\n",
       " array([0.04524991], dtype=float32),\n",
       " array([0.0449723], dtype=float32),\n",
       " array([0.04464957], dtype=float32),\n",
       " array([0.0445641], dtype=float32),\n",
       " array([0.04434803], dtype=float32),\n",
       " array([0.04427049], dtype=float32),\n",
       " array([0.0441733], dtype=float32),\n",
       " array([0.04411736], dtype=float32),\n",
       " array([0.04396942], dtype=float32),\n",
       " array([0.04388431], dtype=float32),\n",
       " array([0.04382455], dtype=float32),\n",
       " array([0.04319158], dtype=float32),\n",
       " array([0.04316664], dtype=float32),\n",
       " array([0.04308638], dtype=float32),\n",
       " array([0.04274625], dtype=float32),\n",
       " array([0.04274359], dtype=float32),\n",
       " array([0.04229504], dtype=float32),\n",
       " array([0.04215491], dtype=float32),\n",
       " array([0.04200742], dtype=float32),\n",
       " array([0.04183605], dtype=float32),\n",
       " array([0.04169112], dtype=float32),\n",
       " array([0.04164177], dtype=float32),\n",
       " array([0.0414744], dtype=float32),\n",
       " array([0.04146916], dtype=float32),\n",
       " array([0.04120988], dtype=float32),\n",
       " array([0.041107], dtype=float32),\n",
       " array([0.04084688], dtype=float32),\n",
       " array([0.04083619], dtype=float32),\n",
       " array([0.04059935], dtype=float32),\n",
       " array([0.04041994], dtype=float32),\n",
       " array([0.04004431], dtype=float32),\n",
       " array([0.04003164], dtype=float32),\n",
       " array([0.0397605], dtype=float32),\n",
       " array([0.03955999], dtype=float32),\n",
       " array([0.03925055], dtype=float32),\n",
       " array([0.03912067], dtype=float32),\n",
       " array([0.0391005], dtype=float32),\n",
       " array([0.03902471], dtype=float32),\n",
       " array([0.03900683], dtype=float32),\n",
       " array([0.03893155], dtype=float32),\n",
       " array([0.03892258], dtype=float32),\n",
       " array([0.03881076], dtype=float32),\n",
       " array([0.0385845], dtype=float32),\n",
       " array([0.03837985], dtype=float32),\n",
       " array([0.03837937], dtype=float32),\n",
       " array([0.03815478], dtype=float32),\n",
       " array([0.03810656], dtype=float32),\n",
       " array([0.03791821], dtype=float32),\n",
       " array([0.03775543], dtype=float32),\n",
       " array([0.03775212], dtype=float32),\n",
       " array([0.03775048], dtype=float32),\n",
       " array([0.03756124], dtype=float32),\n",
       " array([0.03746405], dtype=float32),\n",
       " array([0.03735593], dtype=float32),\n",
       " array([0.03704685], dtype=float32),\n",
       " array([0.03685629], dtype=float32),\n",
       " array([0.03674164], dtype=float32),\n",
       " array([0.03667122], dtype=float32),\n",
       " array([0.03665996], dtype=float32),\n",
       " array([0.03656867], dtype=float32),\n",
       " array([0.03639671], dtype=float32),\n",
       " array([0.03633487], dtype=float32),\n",
       " array([0.03625163], dtype=float32),\n",
       " array([0.0361526], dtype=float32),\n",
       " array([0.03614876], dtype=float32),\n",
       " array([0.03577816], dtype=float32),\n",
       " array([0.03550875], dtype=float32),\n",
       " array([0.03539291], dtype=float32),\n",
       " array([0.03516081], dtype=float32),\n",
       " array([0.03484663], dtype=float32),\n",
       " array([0.0347487], dtype=float32),\n",
       " array([0.03462952], dtype=float32),\n",
       " array([0.03448904], dtype=float32),\n",
       " array([0.03415468], dtype=float32),\n",
       " array([0.03412941], dtype=float32),\n",
       " array([0.03412026], dtype=float32),\n",
       " array([0.03397566], dtype=float32),\n",
       " array([0.0338043], dtype=float32),\n",
       " array([0.03359103], dtype=float32),\n",
       " array([0.0333854], dtype=float32),\n",
       " array([0.0329321], dtype=float32),\n",
       " array([0.03271198], dtype=float32),\n",
       " array([0.0324882], dtype=float32),\n",
       " array([0.03242615], dtype=float32),\n",
       " array([0.03216031], dtype=float32),\n",
       " array([0.03198954], dtype=float32),\n",
       " array([0.03192005], dtype=float32),\n",
       " array([0.03150648], dtype=float32),\n",
       " array([0.03136781], dtype=float32),\n",
       " array([0.0311943], dtype=float32),\n",
       " array([0.03106976], dtype=float32),\n",
       " array([0.03105012], dtype=float32),\n",
       " array([0.03097406], dtype=float32),\n",
       " array([0.0309557], dtype=float32),\n",
       " array([0.0306457], dtype=float32),\n",
       " array([0.03058544], dtype=float32),\n",
       " array([0.02988839], dtype=float32),\n",
       " array([0.02913186], dtype=float32),\n",
       " array([0.02902913], dtype=float32),\n",
       " array([0.0288749], dtype=float32),\n",
       " array([0.02873841], dtype=float32),\n",
       " array([0.02856922], dtype=float32),\n",
       " array([0.02852422], dtype=float32),\n",
       " array([0.02851552], dtype=float32),\n",
       " array([0.02850801], dtype=float32),\n",
       " array([0.02836984], dtype=float32),\n",
       " array([0.0283449], dtype=float32),\n",
       " array([0.02829391], dtype=float32),\n",
       " array([0.02827764], dtype=float32),\n",
       " array([0.02819967], dtype=float32),\n",
       " array([0.02815825], dtype=float32),\n",
       " array([0.02775499], dtype=float32),\n",
       " array([0.02762106], dtype=float32),\n",
       " array([0.0271531], dtype=float32),\n",
       " array([0.02693206], dtype=float32),\n",
       " array([0.0266473], dtype=float32),\n",
       " array([0.02659136], dtype=float32),\n",
       " array([0.0265581], dtype=float32),\n",
       " array([0.02638724], dtype=float32),\n",
       " array([0.02624103], dtype=float32),\n",
       " array([0.02607706], dtype=float32),\n",
       " array([0.02583715], dtype=float32),\n",
       " array([0.02533621], dtype=float32),\n",
       " array([0.02515939], dtype=float32),\n",
       " array([0.02463594], dtype=float32),\n",
       " array([0.02415475], dtype=float32),\n",
       " array([0.0233103], dtype=float32),\n",
       " array([0.02241406], dtype=float32),\n",
       " array([0.02212578], dtype=float32),\n",
       " array([0.0211989], dtype=float32),\n",
       " array([0.02074054], dtype=float32),\n",
       " array([0.02069291], dtype=float32),\n",
       " array([0.01992196], dtype=float32),\n",
       " array([0.01881489], dtype=float32)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(reversed(sorted(model.predict(test_predictors)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Algorithm 2 - Random Forests + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import xgboost as xgb\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'objective':'binary:logistic',\n",
    "    'learning_rate':0.1,\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 1000\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier(**param_dist)\n",
    "\n",
    "clf.fit(\n",
    "    train_predictors, train_targets,\n",
    "    eval_set=[(train_predictors, train_targets), (test_predictors, test_targets)],\n",
    "    eval_metric='logloss',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "evals_result = clf.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# d=3 -> 0.07975 -> 0.22400\n",
    "# d =2 -> 0.13282 -> 0.21438\n",
    "# d = 1 -> 0.18601 -> 0.20780\n",
    "\n",
    "prediction = clf.predict(test_predictors)\n",
    "prediction_probability = clf.predict_proba(test_predictors)\n",
    "#prediction_probability[7]\n",
    "df_pred_test = pd.DataFrame({\n",
    "    \"P\": prediction,\n",
    "    \"R\": test_targets\n",
    "})\n",
    "sum(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pruning_start = 300\n",
    "pruning_end = 400\n",
    "\n",
    "# pruned_predictions = prediction_probability.T[1][pruning_start:pruning_end]\n",
    "# x = pd.DataFrame(pruned_predictions)\n",
    "# pruned_predictions = x[x > 0.0000005].to_numpy()\n",
    "\n",
    "pruned_predictions = prediction[pruning_start:pruning_end]\n",
    "\n",
    "pruned_test_targets = test_targets[pruning_start:pruning_end]\n",
    "plt.plot(pruned_predictions, c=\"r\")\n",
    "plt.plot(pruned_test_targets, c=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_supporting_predictors = supporting_predictors[-test_predictors.shape[0]:]\n",
    "test_supporting_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_adj_close = test_predictors[\"Adj Close\"].to_numpy()\n",
    "test_ema = test_supporting_predictors[\"RAW-EMA-5\"].to_numpy()\n",
    "\n",
    "test_target_indices = np.array(list(np.where(test_targets == 1)[0]))\n",
    "test_prediction_indices = np.array(list(np.where(prediction == 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "window_start = 0\n",
    "window_end = 100\n",
    "\n",
    "# Pruning for vizualization\n",
    "windowed_test_target_indices = test_target_indices[test_target_indices < window_end]\n",
    "windowed_test_target_indices = windowed_test_target_indices[windowed_test_target_indices >= window_start]\n",
    "windowed_test_target_indices = windowed_test_target_indices - window_start\n",
    "\n",
    "windowed_prediction_indices = test_prediction_indices[test_prediction_indices < window_end]\n",
    "windowed_prediction_indices = windowed_prediction_indices[windowed_prediction_indices >= window_start]\n",
    "windowed_prediction_indices = windowed_prediction_indices - window_start\n",
    "\n",
    "windowed_test_adj_close = test_adj_close[window_start:window_end]\n",
    "windowed_test_ema = test_ema[window_start:window_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.plot(windowed_test_adj_close)\n",
    "plt.plot(windowed_test_ema)\n",
    "plt.plot(windowed_test_target_indices, windowed_test_adj_close[windowed_test_target_indices], \"^\")\n",
    "plt.plot(windowed_prediction_indices, windowed_test_adj_close[windowed_prediction_indices], \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model2 = XGBClassifier(objective='multiclass:softmax', learning_rate = 0.1,\n",
    "              max_depth = 1, n_estimators = 330)\n",
    "model2.fit(x_train, y_train)\n",
    "preds = model2.predict(x_test)\n",
    "print(sum(preds==y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Algorithm 1 - Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "number_of_trees = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "rf = RandomForestRegressor(n_estimators=number_of_trees, random_state=42)\n",
    "rf.fit(train_predictors, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Test Set Prediction\n",
    "predictions = rf.predict(test_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_targets)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'Points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "manual_comparison = pd.DataFrame({\n",
    "    'Predictions': predictions,\n",
    "    'Actual': test_targets,\n",
    "})\n",
    "\n",
    "#list(manual_comparison.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pruning_constant = 100\n",
    "pruned_predictions = predictions[:pruning_constant]\n",
    "pruned_test_targets = test_targets[:pruning_constant]\n",
    "plt.plot(pruned_predictions, c=\"r\")\n",
    "plt.plot(pruned_test_targets, c=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_target_indices = list(np.where(test_targets == 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Constants\n",
    "thresholded_prediction_indices = list(np.where(predictions > 0.40)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adj_close = test_predictors[\"Adj Close\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "pruning_constant = 300\n",
    "\n",
    "# Pruning for vizualization\n",
    "test_target_indices = np.array(test_target_indices)\n",
    "thresholded_prediction_indices = np.array(thresholded_prediction_indices)\n",
    "\n",
    "test_target_indices = test_target_indices[test_target_indices < pruning_constant]\n",
    "thresholded_prediction_indices = thresholded_prediction_indices[thresholded_prediction_indices < pruning_constant]\n",
    "adj_close = adj_close[:pruning_constant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.plot(adj_close)\n",
    "plt.plot(test_target_indices, adj_close[test_target_indices], \"^\")\n",
    "plt.plot(thresholded_prediction_indices, adj_close[thresholded_prediction_indices], \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#### Importnace Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "importance_data = \"\"\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for\n",
    "                       feature, importance in\n",
    "                       zip(predictors_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1],\n",
    "                             reverse=True)\n",
    "# Print out the feature and importances\n",
    "importance_data = ['Variable: {:20} Importance: {}'.format(*pair) for pair in feature_importances]\n",
    "feature_importances\n",
    "# for pair in feature_importances:\n",
    "#     print(pair[0] + \" : \" + str(pair[1]))\n",
    "#print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the dataset\n",
    "labels = []\n",
    "values = []\n",
    "for pair in feature_importances:\n",
    "    labels.append(pair[0])\n",
    "    values.append(pair[1])\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(labels, values, color ='maroon', width = 0.75)\n",
    "\n",
    "plt.xlabel(\"Predictor\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Predictor Importance\")\n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importance_data = \"\"\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for\n",
    "                       feature, importance in\n",
    "                       zip(predictors_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1],\n",
    "                             reverse=True)\n",
    "# Print out the feature and importances\n",
    "importance_data = ['Variable: {:20} Importance: {}'.format(*pair) for pair in feature_importances]\n",
    "feature_importances\n",
    "# for pair in feature_importances:\n",
    "#     print(pair[0] + \" : \" + str(pair[1]))\n",
    "#print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating the dataset\n",
    "labels = []\n",
    "values = []\n",
    "for pair in feature_importances:\n",
    "    labels.append(pair[0])\n",
    "    values.append(pair[1])\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(labels, values, color ='maroon', width = 0.75)\n",
    "\n",
    "plt.xlabel(\"Predictor\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Predictor Importance\")\n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 4 - RNNs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}